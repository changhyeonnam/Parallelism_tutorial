### Parallelism_tutorial

This repository is for Parallelism tutorial using pytorch.

This project is still under development.

### reference
1. [pytorch tutorial docs](https://pytorch.org/tutorials/intermediate/dist_tuto.html)
2. [post from matthew l (written in korean)](https://medium.com/daangn/pytorch-multi-gpu-%ED%95%99%EC%8A%B5-%EC%A0%9C%EB%8C%80%EB%A1%9C-%ED%95%98%EA%B8%B0-27270617936b)
3. [post from Thomas Wolf](https://medium.com/huggingface/training-larger-batches-practical-tips-on-1-gpu-multi-gpu-distributed-setups-ec88c3e51255)
4. [post form Ceshine Lee](https://medium.com/the-artificial-impostor/use-nvidia-apex-for-easy-mixed-precision-training-in-pytorch-46841c6eed8c)